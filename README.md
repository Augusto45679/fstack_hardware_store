# Fullstack Hardware Store Scraper & Comparator

Una aplicaciÃ³n fullstack moderna diseÃ±ada para scrapear, almacenar y comparar precios de hardware de computaciÃ³n de mÃºltiples tiendas argentinas (como Compragamer y Mercado Libre). El sistema permite a los usuarios buscar productos, ver historiales de precios y encontrar las mejores ofertas.

## ğŸš€ CaracterÃ­sticas Principales

- **Scraping Automatizado**: ExtracciÃ³n de datos de productos e imÃ¡genes utilizando **Scrapy**.
- **GestiÃ³n de ImÃ¡genes Inteligente**: IntegraciÃ³n con **Cloudinary** para alojamiento de imÃ¡genes con detecciÃ³n de duplicados.
- **BÃºsqueda Avanzada**: API RESTful con soporte para bÃºsqueda por texto, filtros de precio, tienda y paginaciÃ³n.
- **Historial de Precios**: Seguimiento de la evoluciÃ³n de precios a lo largo del tiempo.
- **ComparaciÃ³n de Productos**: Herramientas para comparar el mismo producto entre diferentes vendedores.
- **Interfaz Moderna**: Frontend desarrollado con **Next.js 16** y **Shadcn/UI**, con soporte para modo oscuro y diseÃ±o responsivo.

## ğŸ›  Tech Stack

### Backend (`backend_scrapProject`)
- **Framework**: FastAPI
- **Base de Datos**: MongoDB (Motor driver para async)
- **Procesamiento de Datos**: Pandas
- **Lenguaje**: Python 3.10+

### Frontend (`front_scrapProject`)
- **Framework**: Next.js 16 (App Router)
- **LibrerÃ­a UI**: React 19
- **Estilos**: TailwindCSS
- **Componentes**: Shadcn/UI
- **GrÃ¡ficos**: Recharts
- **Iconos**: Lucide React

### Scraper
- **Framework**: Scrapy
- **Almacenamiento de ImÃ¡genes**: Cloudinary API

## ğŸ“‹ Prerrequisitos

- Python 3.10 o superior
- Node.js 18 o superior
- MongoDB (corriendo localmente o cluster de Atlas)

## âš™ï¸ InstalaciÃ³n y EjecuciÃ³n

### 1. ConfiguraciÃ³n del Backend

Navega al directorio del backend:
```bash
cd backend_scrapProject
```

Crea un entorno virtual y actÃ­valo:
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

Instala las dependencias:
```bash
pip install -r requirements.txt
```

Configura las variables de entorno (crea un archivo `.env` en `backend_scrapProject`):
```env
MONGO_URI=mongodb://localhost:27017
MONGO_DATABASE=hardware_db
MONGO_COLLECTION=products
# Credenciales de Cloudinary (si vas a correr los scrapers)
CLOUDINARY_CLOUD_NAME=tu_cloud_name
CLOUDINARY_API_KEY=tu_api_key
CLOUDINARY_API_SECRET=tu_api_secret
```

Ejecuta el servidor de desarrollo:
```bash
uvicorn app.main:app --reload
```
El backend estarÃ¡ disponible en `http://localhost:8000`.
DocumentaciÃ³n interactiva (Swagger UI): `http://localhost:8000/docs`.

### 2. ConfiguraciÃ³n del Frontend

Navega al directorio del frontend:
```bash
cd front_scrapProject
```

Instala las dependencias:
```bash
npm install
```

Ejecuta el servidor de desarrollo:
```bash
npm run dev
```
La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:3000`.

## ğŸ“‚ Estructura del Proyecto

```
/
â”œâ”€â”€ backend_scrapProject/    # API FastAPI y lÃ³gica de negocio
â”‚   â”œâ”€â”€ app/                 # Routers, modelos y configuraciÃ³n de DB
â”‚   â””â”€â”€ ...
â”œâ”€â”€ front_scrapProject/      # AplicaciÃ³n Next.js
â”‚   â”œâ”€â”€ components/          # Componentes UI reutilizables
â”‚   â”œâ”€â”€ app/                 # PÃ¡ginas y layouts (App Router)
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md                # DocumentaciÃ³n del proyecto
```

## ğŸ” Endpoints Principales

- `GET /products`: Listado paginado de productos.
- `GET /products/search`: BÃºsqueda con filtros (query, min_price, max_price, store).
- `GET /products/{id}`: Detalles de un producto.
- `GET /products/{id}/history`: Historial de precios.
- `GET /products/stats`: EstadÃ­sticas y mejores ofertas.